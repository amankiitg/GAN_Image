{"cells":[{"cell_type":"code","execution_count":null,"id":"8938e9c5","metadata":{"id":"8938e9c5"},"outputs":[],"source":["from numpy import expand_dims\n","from numpy import zeros\n","from numpy import ones\n","from numpy import vstack\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras.datasets import cifar10\n","from keras.optimizers import Adam\n","from keras.optimizers import RMSprop\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Dropout\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"id":"OsJNtrmoUAfz"},"id":"OsJNtrmoUAfz","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"qsRgAfA_Kcd-","metadata":{"id":"qsRgAfA_Kcd-"},"source":["# Kaggle"]},{"cell_type":"code","execution_count":null,"id":"LZ8pHAJ4JWso","metadata":{"id":"LZ8pHAJ4JWso"},"outputs":[],"source":["# !pip install kaggle"]},{"cell_type":"code","source":["!mkdir ~/.kaggle"],"metadata":{"id":"dcyW4c1nUPzJ"},"id":"dcyW4c1nUPzJ","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"rvk-Nk2AKEbJ","metadata":{"id":"rvk-Nk2AKEbJ"},"outputs":[],"source":["!cp kaggle.json ~/.kaggle/"]},{"cell_type":"code","execution_count":null,"id":"a9EQCF8sKU3G","metadata":{"id":"a9EQCF8sKU3G"},"outputs":[],"source":["!chmod 600 kaggle.json"]},{"cell_type":"code","execution_count":null,"id":"I4QBc85LKiCe","metadata":{"id":"I4QBc85LKiCe"},"outputs":[],"source":["# !kaggle datasets list"]},{"cell_type":"code","execution_count":null,"id":"LlBJq_HKNgNf","metadata":{"id":"LlBJq_HKNgNf"},"outputs":[],"source":["!kaggle datasets download -d jessicali9530/celeba-dataset"]},{"cell_type":"code","execution_count":null,"id":"mJF7JPSeNs5J","metadata":{"id":"mJF7JPSeNs5J"},"outputs":[],"source":["!unzip celeba-dataset.zip"]},{"cell_type":"markdown","id":"iL_n7UruSInn","metadata":{"id":"iL_n7UruSInn"},"source":["# Generator and Discriminator"]},{"cell_type":"code","execution_count":null,"id":"a4ab13f9","metadata":{"id":"a4ab13f9"},"outputs":[],"source":["# Define the generator networ.\n","# This example comsider a CNN. Depending on the nature of the problem, \n","# it can be made more complex, and also different models such as VGG can also be used\n","\n","def Generator(latentShape,imgShape):\n","    model = Sequential()\n","    # foundation for 4x4 image\n","    n_nodes = 256 * 4 * 4\n","    model.add(Dense(n_nodes, input_shape=latentShape))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Reshape((4, 4, 256)))\n","    # upsample to 8x8\n","    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # upsample to 16x16\n","    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # upsample to 32x32\n","    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # upsample to 64X64\n","    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # upsample to 128X128\n","    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # output layer\n","    model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n","    model.summary()\n","    \n","    # opt = RMSprop(learning_rate=0.001)  #Learning rate \n","    opt = Adam(0.0002, 0.5)  #Learning rate and momentum.\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"id":"b300767d","metadata":{"id":"b300767d"},"outputs":[],"source":["def Discriminator(imgShape):\n","\n","    model = Sequential()\n","    # normal\n","    model.add(Conv2D(256, (3,3), padding='same', input_shape=imgShape))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # downsample\n","    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # downsample\n","    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # downsample\n","    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # downsample\n","    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # downsample\n","    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # downsample\n","    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # classifier\n","    model.add(Flatten())\n","    model.add(Dropout(0.4))\n","    model.add(Dense(1, activation='sigmoid'))\n","    model.summary()\n","    # compile model\n","    # opt = RMSprop(learning_rate=0.001)\n","    opt = Adam(lr=0.0002, beta_1=0.5)\n","    \n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"id":"a9a2c189","metadata":{"id":"a9a2c189"},"outputs":[],"source":["# Combine the generator and discriminator models into one pipeline\n","def GAN(g, d):\n","    # Set the discriminator parameters to false\n","    d.trainable = False\n","    \n","    # Create a GAN model = generator + discriminator\n","    model = Sequential()\n","    model.add(g)\n","    model.add(d)   # disciminator takes output of generator as input\n","    \n","    # Set compile parameters\n","    opt = Adam(0.0002, 0.5)  #Learning rate and momentum.\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    \n","    return model"]},{"cell_type":"markdown","id":"f567625c","metadata":{"id":"f567625c"},"source":["# Testing the data"]},{"cell_type":"code","execution_count":null,"id":"57b3c13c","metadata":{"id":"57b3c13c"},"outputs":[],"source":["# (cifar10X, _), (_, _) = cifar10.load_data()"]},{"cell_type":"code","execution_count":null,"id":"929e178b","metadata":{"id":"929e178b"},"outputs":[],"source":["# cifar10X.shape"]},{"cell_type":"code","execution_count":null,"id":"3600f27b","metadata":{"id":"3600f27b","scrolled":true},"outputs":[],"source":["# import tensorflow_datasets as tfds\n","# ds, ds_info = tfds.load('cifar10', split='train', with_info=True)\n","# fig = tfds.show_examples(ds, ds_info)\n","# fig.show()"]},{"cell_type":"markdown","id":"4611a766","metadata":{"id":"4611a766"},"source":["# Loading Celebrity Face Image Data"]},{"cell_type":"code","execution_count":null,"id":"sS9H2cs7SNRB","metadata":{"id":"sS9H2cs7SNRB"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"50a1a66f","metadata":{"id":"50a1a66f"},"outputs":[],"source":["# !pip install scikit-image"]},{"cell_type":"code","execution_count":null,"id":"67927e9e","metadata":{"id":"67927e9e"},"outputs":[],"source":["import os\n","import numpy as np\n","from skimage.io import imread\n","from skimage.transform import resize\n","\n","# path = '/Users/amankesarwani/Downloads/archive/img_align_celeba/img_align_celeba/'\n","# path = '/content/drive/My Drive/img_align_celeba/'\n","path = '/content/img_align_celeba/img_align_celeba/'\n","image_data_arr = []\n","import random\n","SEED = 448\n","\n","imgShape = (128,128,3)\n","\n","myList = os.listdir(path)\n","random.seed(SEED)\n","random.shuffle(myList)\n","len(myList)"]},{"cell_type":"code","execution_count":null,"id":"guVqLJIwShi6","metadata":{"id":"guVqLJIwShi6","scrolled":true},"outputs":[],"source":["for i in range(40000):#len(myList):   \n","#     print(img)\n","    if(i%1000==0):\n","        print(i)\n","    img = myList[i]\n","    img_array=imread(os.path.join(path,img))\n","#     print(img_array.shape)\n","    img_resized=resize(img_array,imgShape)   \n","    image_data_arr.append(img_resized)"]},{"cell_type":"code","source":["image_data_arr = np.array(image_data_arr)\n","# scale the original values [0,255] to [-1,1]\n","image_data_arr = (image_data_arr.astype('float32') - 0.5) / 0.5"],"metadata":{"id":"-MO14SK9XFVb"},"id":"-MO14SK9XFVb","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"c96b8a09","metadata":{"id":"c96b8a09"},"outputs":[],"source":["# img_array=imread(os.path.join(path,img))\n","# print(img_array.shape)"]},{"cell_type":"code","execution_count":null,"id":"c768a3b0","metadata":{"id":"c768a3b0"},"outputs":[],"source":["# np.array(image_data_arr).shape"]},{"cell_type":"code","execution_count":null,"id":"147cdd7c","metadata":{"id":"147cdd7c"},"outputs":[],"source":["# np.max(np.array(image_data_arr).flatten())"]},{"cell_type":"code","execution_count":null,"id":"7bd13bf4","metadata":{"id":"7bd13bf4"},"outputs":[],"source":["# np.min(np.array(image_data_arr).flatten())"]},{"cell_type":"markdown","id":"0SSM-g4UR-Dq","metadata":{"id":"0SSM-g4UR-Dq"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"id":"99ac76c5","metadata":{"id":"99ac76c5"},"outputs":[],"source":["# output_folder = '/Users/amankesarwani/Documents/DLXR/Deep Learning Advanced/outputrms/'\n","output_folder = '/content/drive/My Drive/adam/'"]},{"cell_type":"code","execution_count":null,"id":"1a1a6c59","metadata":{"id":"1a1a6c59"},"outputs":[],"source":["# load the MNIST dataset and change its shape to 28x28x1\n","def get_real_samples():\n","    # load MNIST dataset without its class labels\n","    # (cifar10X, _), (_, _) = cifar10.load_data()\n","    \n","    cifar10X = np.array(image_data_arr)\n","    # scale the original values [0,255] to [-1,1]\n","    X = (cifar10X.astype('float32') - 0.5) / 0.5\n","    \n","    return X"]},{"cell_type":"code","execution_count":null,"id":"8ebee1bd","metadata":{"id":"8ebee1bd"},"outputs":[],"source":["# While training the discriminator, only a random batch are considered\n","def get_random_real_samples(dataset, n):\n","    # choose random n samples\n","    print(dataset.shape)\n","    X = dataset[np.random.randint(0, dataset.shape[0], n)]\n","    \n","    # Generate Class labels of real samples as 1\n","    y = np.ones((n, 1))\n","    return X, y"]},{"cell_type":"code","execution_count":null,"id":"42b7e9b3","metadata":{"id":"42b7e9b3"},"outputs":[],"source":["# Generate n number of noise samples  for the generator\n","def generate_noise_samples(noise_dim, n):\n","    ld=np.prod(noise_dim) # convert noise_dim shape (28,28,1) to 28x28x1\n","    \n","    # generate n number of random noise samples of dim ld\n","    x_input = np.random.normal(0,1, (n, ld))\n","    # reshape into a batch of inputs for the network\n","    #x_input = x_input.reshape(n_samples, ld)\n","    return x_input"]},{"cell_type":"code","execution_count":null,"id":"460405cf","metadata":{"id":"460405cf"},"outputs":[],"source":["# Generate FAKE samles using Generator from the noise samples\n","def generate_fake_samples(g, noise_dim, n):\n","\n","    x_input = generate_noise_samples(noise_dim, n)\n","    \n","    # Generate Fake samples and its class label as 0\n","    X = g.predict(x_input)\n","    y = np.zeros((n, 1))\n","    \n","    return X, y"]},{"cell_type":"code","execution_count":null,"id":"gGJ5y-w1inPd","metadata":{"id":"gGJ5y-w1inPd"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_rate(r,f,g,title,i):\n"," \n","    plt.figure()\n","    plt.plot(r,color='green',label='Real',linestyle='--')\n","    plt.plot(f,color='red',label='Fake',linestyle='--')\n","    data = np.array([r,f])\n","    plt.plot(np.average(data, axis=0),color='blue',label='Discriminator')\n","    plt.plot(g,color='gray',label='Generator')\n","\n","\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(title)\n","    plt.legend()\n","\n","    if(i%100==0):\n","        filename = output_folder+title+'plot_%d.png' % (i)\n","        plt.savefig(filename)\n","        plt.show()\n","        plt.close()\n","    else:\n","        plt.show()\n","  "]},{"cell_type":"code","execution_count":null,"id":"xzs2VZ5dNrmD","metadata":{"id":"xzs2VZ5dNrmD"},"outputs":[],"source":["# plt.figure()\n","# plt.plot([1,2,3],color='green',label='Real')\n","# plt.plot([3,2,1],color='red',label='Fake')\n","# # data = np.array([r,f])\n","# # plt.plot(np.average(data, axis=0),color='blue',label='Discriminator',linestyle='--')\n","# # plt.plot(g,color='k',label='Generator')\n","\n","\n","# plt.xlabel(\"Epochs\")\n","# plt.ylabel('Test')\n","# plt.legend()\n","# # plt.show()\n","# filename = '/content/drive/My Drive/output/'+'Test'+'plot_%d.png' % (1)\n","# plt.savefig(filename)\n","# plt.show()\n","# plt.close()"]},{"cell_type":"code","execution_count":null,"id":"08adc03e","metadata":{"id":"08adc03e"},"outputs":[],"source":["# ----------------\n","# For each epoch, randomely select a batch of real and fake images and train the discriminator and GAN\n","# ---------------\n","from IPython.display import clear_output\n","def train(g, d, gan, dataset, noise_dim, epochs, batch):\n","\n","    k = int(dataset.shape[0]/batch)\n","    rl,ra = [],[]\n","    fl,fa = [],[]\n","    gl,ga = [],[]\n","    for i in range(epochs):\n","        if(i%2==0):\n","            #print('Waiting to clear')\n","            clear_output(wait=True)\n","        for j in range(k):\n","            # Train discriminator with real and random samples\n","            #print('Discriminator Training')\n","            X_real, y_real = get_random_real_samples(dataset, batch)\n","            r_error, r_acc = d.train_on_batch(X_real, y_real)\n","            X_fake, y_fake = generate_fake_samples(g, noise_dim, batch)\n","            f_error, f_acc = d.train_on_batch(X_fake, y_fake)\n","            \n","            \n","            # Train GAN\n","            #print('GAN Training')\n","            X_gan = generate_noise_samples(noise_dim, batch)\n","            y_gan = np.ones((batch, 1))\n","            g_error, g_acc = gan.train_on_batch(X_gan, y_gan)\n","            \n","        # Batch training loss\n","        rl.append(r_error)\n","        fl.append(f_error)\n","        gl.append(g_error)\n","        ra.append(r_acc)\n","        fa.append(f_acc)\n","        ga.append(g_acc)\n","        \n","        print('Epoch %d -> Discriminator loss %f GAN loss %f' % (i, (r_error+f_error)/2, g_error))\n","        print('RE ',r_error,' FE ',f_error,' RA ',r_acc,' FA ',f_acc)\n","        print('Epoch %d -> Discriminator acc %f GAN acc %f' % (i, (r_acc+f_acc)/2, g_acc))\n","            \n","        # Save the generated images every 100 epoch    \n","        if((i%10==0)):\n","            save_plot(X_fake,g,i)\n","        if((i%10==0)):\n","            save_20plot(X_fake,g,i)\n","            filename = output_folder+'results_%d.txt' % (i)\n","            f = open(filename,'w')\n","            print('Epoch %d -> Discriminator loss %f GAN loss %f' % (i, (r_error+f_error)/2, g_error), file=f)\n","            print('RE ',r_error,' FE ',f_error,' RA ',r_acc,' FA ',f_acc, file=f)\n","            print('Epoch %d -> Discriminator acc %f GAN acc %f' % (i, (r_acc+f_acc)/2, g_acc), file=f)\n","            f.close()\n","        \n","        # if((i==3)|(i==5000)|(i==10000)):\n","        #   plot_rate(rl,fl,gl,'Loss '+str(i))\n","        #   plot_rate(ra,fa,ga,'Accuracy'+str(i))\n","\n","        plot_rate(rl,fl,gl,'Loss',i)\n","        plot_rate(ra,fa,ga,'Accuracy',i)"]},{"cell_type":"code","execution_count":null,"id":"95730d06","metadata":{"id":"95730d06"},"outputs":[],"source":["# create and save a plot of generated images\n","def save_plot(fake,g,epoch):\n","    \n","    # scale from [-1,1] to [0,1]\n","    fake = (fake + 1) / 2.0\n","    # plot images\n","    \n","    plt.imshow(fake[0])\n","    filename = output_folder+'face_%d.png' % (epoch+1)\n","    plt.savefig(filename)\n","    plt.close()    "]},{"cell_type":"code","execution_count":null,"id":"FOreADmcAuyh","metadata":{"id":"FOreADmcAuyh"},"outputs":[],"source":["def save_20plot(fake,g,epoch):\n","    \n","    # scale from [-1,1] to [0,1]\n","    fake = (fake + 1) / 2.0\n","    # plot images\n","    \n","    for i in range(20):\n","        plt.imshow(fake[i])\n","        filename = output_folder+str(i)+'face_%d.png' % (epoch+1)\n","        plt.savefig(filename)\n","        plt.close()\n","\n","    r,c = 5,5\n","    fig, axs = plt.subplots(r, c)\n","    cnt = 0\n","    for i in range(r):\n","        for j in range(c):\n","            axs[i,j].imshow(fake[cnt, :,:,0])\n","            axs[i,j].axis('off')\n","            cnt += 1\n","    fig.savefig(output_folder+'facegrid_%d.png' % epoch)\n","    plt.close()"]},{"cell_type":"markdown","id":"NMrK8X5FSDFn","metadata":{"id":"NMrK8X5FSDFn"},"source":["# Run"]},{"cell_type":"code","execution_count":null,"id":"iChDLcIGRTuu","metadata":{"id":"iChDLcIGRTuu"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"id":"P_J5IopNRU5R","metadata":{"id":"P_J5IopNRU5R"},"outputs":[],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"id":"7a0f9b3d","metadata":{"id":"7a0f9b3d"},"outputs":[],"source":["# size of the noise input\n","noiseShape = (1000,)\n","\n","# create the discriminator\n","d = Discriminator(imgShape)\n","# create the generator\n","g = Generator(noiseShape, imgShape)\n","# create the gan\n","gan = GAN(g, d)\n","# load image data\n","# dataset = get_real_samples()"]},{"cell_type":"code","execution_count":null,"id":"ce73b037","metadata":{"id":"ce73b037"},"outputs":[],"source":["# train model\n","train(g, d, gan, image_data_arr, noiseShape, 10001, 128)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["qsRgAfA_Kcd-","iL_n7UruSInn","f567625c","4611a766","0SSM-g4UR-Dq"],"machine_shape":"hm","provenance":[{"file_id":"19Yz_esWjF_p4w1OxBDFYitXqwpm7uR8j","timestamp":1673878321109}],"private_outputs":true},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}